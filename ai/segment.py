# Ultralytics YOLO ğŸš€, AGPL-3.0 license
"""
YOLO11 åˆ†å‰²æ¨¡å‹ ONNXRuntime
    åŠŸèƒ½1: æ”¯æŒä¸ç”¨å°ºå¯¸å›¾åƒçš„è¾“å…¥
    åŠŸèƒ½2: æ”¯æŒå¯è§†åŒ–åˆ†å‰²ç»“æœ
"""

import argparse
import cv2
import numpy as np
import onnxruntime as ort
import time
import torch

# ç±»å¤–å®šä¹‰ç±»åˆ«æ˜ å°„å…³ç³»ï¼Œä½¿ç”¨å­—å…¸æ ¼å¼
CLASS_NAMES = {
    0: 'class_name1',  # ç±»åˆ« 0 åç§°
    1: 'class_name2'  # ç±»åˆ« 1 åç§°
    # å¯ä»¥æ·»åŠ æ›´å¤šç±»åˆ«...
}

# å®šä¹‰ç±»åˆ«å¯¹åº”çš„é¢œè‰²ï¼Œæ ¼å¼ä¸º (R, G, B)
CLASS_COLORS = {
    0: (255, 255, 0),  # ç±»åˆ« 0 çš„é¢œè‰²ä¸ºé’é»„è‰²
    1: (255, 0, 0)  # ç±»åˆ« 1 çš„é¢œè‰²ä¸ºçº¢è‰²
    # å¯ä»¥ä¸ºå…¶ä»–ç±»åˆ«æŒ‡å®šé¢œè‰²...
}


class YOLO11Seg:
    def __init__(self, onnx_model):
        # åˆ›å»º Ort æ¨ç†ä¼šè¯ï¼Œé€‰æ‹© CPU æˆ– GPU æä¾›è€…
        self.session = ort.InferenceSession(
            onnx_model,
            providers=["CUDAExecutionProvider", "CPUExecutionProvider"]
            if ort.get_device() == "GPU"
            else ["CPUExecutionProvider"],
        )
        # æ ¹æ® ONNX æ¨¡å‹ç±»å‹é€‰æ‹© Numpy æ•°æ®ç±»å‹ï¼ˆæ”¯æŒ FP32 å’Œ FP16ï¼‰
        self.ndtype = np.half if self.session.get_inputs()[0].type == "tensor(float16)" else np.single

        # è·å–æ¨¡å‹çš„è¾“å…¥å®½åº¦å’Œé«˜åº¦ï¼ˆYOLO11-seg åªæœ‰ä¸€ä¸ªè¾“å…¥ï¼‰
        self.model_height, self.model_width = [x.shape for x in self.session.get_inputs()][0][-2:]

        # æ‰“å°æ¨¡å‹çš„è¾“å…¥å°ºå¯¸
        # print("YOLO11 ğŸš€ å®ä¾‹åˆ†å‰² ONNXRuntime")
        # print("æ¨¡å‹åç§°ï¼š", onnx_model)
        # print(f"æ¨¡å‹è¾“å…¥å°ºå¯¸ï¼šå®½åº¦ = {self.model_width}, é«˜åº¦ = {self.model_height}")

        # åŠ è½½ç±»åˆ«åç§°
        self.classes = CLASS_NAMES

        # åŠ è½½ç±»åˆ«å¯¹åº”çš„é¢œè‰²
        self.class_colors = CLASS_COLORS

    def get_color_for_class(self, class_id):
        return self.class_colors.get(class_id, (255, 255, 255))  # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç±»åˆ«é¢œè‰²ï¼Œè¿”å›ç™½è‰²

    def __call__(self, im0, conf_threshold=0.4, iou_threshold=0.45, nm=32):
        """
        å®Œæ•´çš„æ¨ç†æµç¨‹ï¼šé¢„å¤„ç† -> æ¨ç† -> åå¤„ç†
        Args:
            im0 (Numpy.ndarray): åŸå§‹è¾“å…¥å›¾åƒ
            conf_threshold (float): ç½®ä¿¡åº¦é˜ˆå€¼
            iou_threshold (float): NMS ä¸­çš„ IoU é˜ˆå€¼
            nm (int): æ©è†œæ•°é‡
        Returns:
            boxes (List): è¾¹ç•Œæ¡†åˆ—è¡¨
            segments (List): åˆ†å‰²åŒºåŸŸåˆ—è¡¨
            masks (np.ndarray): [N, H, W] è¾“å‡ºæ©è†œ
        """
        # å›¾åƒé¢„å¤„ç†
        im, ratio, (pad_w, pad_h) = self.preprocess(im0)

        # ONNX æ¨ç†
        infer = time.time()
        preds = self.session.run(None, {self.session.get_inputs()[0].name: im})
        print("æ¨ç†æ—¶é—´ï¼š", time.time() - infer)
        # åå¤„ç†
        boxes, segments, masks = self.postprocess(
            preds,
            im0=im0,
            ratio=ratio,
            pad_w=pad_w,
            pad_h=pad_h,
            conf_threshold=conf_threshold,
            iou_threshold=iou_threshold,
            nm=nm,
        )
        return boxes, segments, masks

    def preprocess(self, img):
        """
        å›¾åƒé¢„å¤„ç†
        Args:
            img (Numpy.ndarray): è¾“å…¥å›¾åƒ
        Returns:
            img_process (Numpy.ndarray): å¤„ç†åçš„å›¾åƒ
            ratio (tuple): å®½é«˜æ¯”ä¾‹
            pad_w (float): å®½åº¦çš„å¡«å……
            pad_h (float): é«˜åº¦çš„å¡«å……
        """
        # è°ƒæ•´è¾“å…¥å›¾åƒå¤§å°å¹¶ä½¿ç”¨ letterbox å¡«å……
        shape = img.shape[:2]  # åŸå§‹å›¾åƒå¤§å°
        new_shape = (self.model_height, self.model_width)
        r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])
        ratio = r, r
        new_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))
        pad_w, pad_h = (new_shape[1] - new_unpad[0]) / 2, (new_shape[0] - new_unpad[1]) / 2  # å¡«å……å®½é«˜
        if shape[::-1] != new_unpad:  # è°ƒæ•´å›¾åƒå¤§å°
            img = cv2.resize(img, new_unpad, interpolation=cv2.INTER_LINEAR)
        top, bottom = int(round(pad_h - 0.1)), int(round(pad_h + 0.1))
        left, right = int(round(pad_w - 0.1)), int(round(pad_w + 0.1))
        img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=(114, 114, 114))

        # è½¬æ¢ï¼šHWC -> CHW -> BGR è½¬ RGB -> é™¤ä»¥ 255 -> contiguous -> æ·»åŠ ç»´åº¦
        img = np.ascontiguousarray(np.einsum("HWC->CHW", img)[::-1], dtype=self.ndtype) / 255.0
        img_process = img[None] if len(img.shape) == 3 else img
        return img_process, ratio, (pad_w, pad_h)

    def postprocess(self, preds, im0, ratio, pad_w, pad_h, conf_threshold, iou_threshold, nm=32):
        """
        æ¨ç†åçš„ç»“æœåå¤„ç†
        Args:
            preds (Numpy.ndarray): æ¥è‡ª ONNX çš„æ¨ç†ç»“æœ
            im0 (Numpy.ndarray): [h, w, c] åŸå§‹è¾“å…¥å›¾åƒ
            ratio (tuple): å®½é«˜æ¯”ä¾‹
            pad_w (float): å®½åº¦çš„å¡«å……
            pad_h (float): é«˜åº¦çš„å¡«å……
            conf_threshold (float): ç½®ä¿¡åº¦é˜ˆå€¼
            iou_threshold (float): IoU é˜ˆå€¼
            nm (int): æ©è†œæ•°é‡
        Returns:
            boxes (List): è¾¹ç•Œæ¡†åˆ—è¡¨
            segments (List): åˆ†å‰²åŒºåŸŸåˆ—è¡¨
            masks (np.ndarray): æ©è†œæ•°ç»„
        """
        t1 = time.time()
        x, protos = preds[0], preds[1]  # è·å–æ¨¡å‹çš„ä¸¤ä¸ªè¾“å‡ºï¼šé¢„æµ‹å’ŒåŸå‹

        # è½¬æ¢ç»´åº¦
        x = np.einsum("bcn->bnc", x)

        # ç½®ä¿¡åº¦è¿‡æ»¤
        x = x[np.amax(x[..., 4:-nm], axis=-1) > conf_threshold]

        # åˆå¹¶è¾¹ç•Œæ¡†ã€ç½®ä¿¡åº¦ã€ç±»åˆ«å’Œæ©è†œ
        x = np.c_[x[..., :4], np.amax(x[..., 4:-nm], axis=-1), np.argmax(x[..., 4:-nm], axis=-1), x[..., -nm:]]

        x = x[x[:, 5] == 0]

        # NMS è¿‡æ»¤
        x = x[cv2.dnn.NMSBoxes(x[:, :4], x[:, 4], conf_threshold, iou_threshold)]

        # è§£æå¹¶è¿”å›ç»“æœ
        if len(x) > 0:
            # è¾¹ç•Œæ¡†æ ¼å¼è½¬æ¢ï¼šä» cxcywh -> xyxy
            x[..., [0, 1]] -= x[..., [2, 3]] / 2
            x[..., [2, 3]] += x[..., [0, 1]]

            # ç¼©æ”¾è¾¹ç•Œæ¡†ï¼Œä½¿å…¶ä¸åŸå§‹å›¾åƒå°ºå¯¸åŒ¹é…
            x[..., :4] -= [pad_w, pad_h, pad_w, pad_h]
            x[..., :4] /= min(ratio)

            # é™åˆ¶è¾¹ç•Œæ¡†åœ¨å›¾åƒè¾¹ç•Œå†…
            x[..., [0, 2]] = x[:, [0, 2]].clip(0, im0.shape[1])
            x[..., [1, 3]] = x[:, [1, 3]].clip(0, im0.shape[0])

            # å¤„ç†æ©è†œ
            masks = self.process_mask(protos[0], x[:, 6:], x[:, :4], im0.shape)

            print('t1',time.time()-t1)
            # å°†æ©è†œè½¬æ¢ä¸ºåˆ†å‰²åŒºåŸŸ
            segments = self.masks2segments(masks)
            return x[..., :6], segments, masks  # è¿”å›è¾¹ç•Œæ¡†ã€åˆ†å‰²åŒºåŸŸå’Œæ©è†œ
        else:
            return [], [], []

    def postprocess1(self, preds, im0, ratio, pad_w, pad_h, conf_threshold, iou_threshold, nm=32):
        """
        ä¼˜åŒ–åçš„æ¨ç†ç»“æœåå¤„ç†
        """
        t1 = time.time()
        x, protos = preds[0], preds[1]  # æ¨¡å‹è¾“å‡º

        # è½¬æ¢ç»´åº¦
        x = x.transpose(0, 2, 1)  # ç­‰æ•ˆäº np.einsum("bcn->bnc", x)

        # ä¸€æ¬¡æ€§è®¡ç®—æœ€å¤§ç½®ä¿¡åº¦å’Œç±»åˆ«ç´¢å¼•
        scores = x[..., 4:-nm]
        max_scores = np.amax(scores, axis=-1)
        class_indices = np.argmax(scores, axis=-1)

        # ç½®ä¿¡åº¦è¿‡æ»¤
        valid_indices = max_scores > conf_threshold
        x = x[valid_indices]
        max_scores = max_scores[valid_indices]
        class_indices = class_indices[valid_indices]

        # åˆå¹¶è¾¹ç•Œæ¡†ã€ç½®ä¿¡åº¦ã€ç±»åˆ«å’Œæ©è†œ
        x = np.c_[x[..., :4], max_scores, class_indices, x[..., -nm:]]

        # ç­›é€‰ç‰¹å®šç±»åˆ«ï¼ˆå¦‚ç±»åˆ«0ï¼‰
        x = x[x[:, 5] == 0]

        # NMS è¿‡æ»¤
        indices = cv2.dnn.NMSBoxes(
            bboxes=x[:, :4].tolist(),
            scores=x[:, 4].tolist(),
            score_threshold=conf_threshold,
            nms_threshold=iou_threshold,
        )
        indices = np.array(indices).flatten()
        x = x[indices]

        # è‹¥å­˜åœ¨æœ‰æ•ˆç»“æœ
        if len(x) > 0:
            # cxcywh -> xyxy è½¬æ¢
            x[..., [0, 1]] -= x[..., [2, 3]] / 2  # å·¦ä¸Šè§’
            x[..., [2, 3]] += x[..., [0, 1]]  # å³ä¸‹è§’

            # ç¼©æ”¾è¾¹ç•Œæ¡†åˆ°åŸå§‹å›¾åƒ
            x[..., :4] -= [pad_w, pad_h, pad_w, pad_h]
            x[..., :4] /= min(ratio)

            # è¾¹ç•Œæ£€æŸ¥
            x[..., [0, 2]] = x[..., [0, 2]].clip(0, im0.shape[1])
            x[..., [1, 3]] = x[..., [1, 3]].clip(0, im0.shape[0])

            # æ©è†œå¤„ç†
            masks = self.process_mask(protos[0], x[:, 6:], x[:, :4], im0.shape)

            print('å¤„ç†æ—¶é—´:', time.time() - t1)

            # è½¬æ¢æ©è†œä¸ºåˆ†å‰²åŒºåŸŸ
            segments = self.masks2segments(masks)
            return x[..., :6], segments, masks
        else:
            return [], [], []

    @staticmethod
    def masks2segments(masks):
        """
        å°†æ©è†œè½¬æ¢ä¸ºåˆ†å‰²åŒºåŸŸ
        Args:
            masks (numpy.ndarray): æ¨¡å‹è¾“å‡ºçš„æ©è†œï¼Œå½¢çŠ¶ä¸º (n, h, w)
        Returns:
            segments (List): åˆ†å‰²åŒºåŸŸçš„åˆ—è¡¨
        """
        segments = []
        for x in masks.astype("uint8"):
            c = cv2.findContours(x, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)[0]  # æ‰¾åˆ°è½®å»“
            if c:
                c = np.array(c[np.array([len(x) for x in c]).argmax()]).reshape(-1, 2)
            else:
                c = np.zeros((0, 2))  # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆ†å‰²åŒºåŸŸï¼Œè¿”å›ç©ºæ•°ç»„
            segments.append(c.astype("float32"))
        return segments

    @staticmethod
    def crop_mask(masks, boxes):
        n, h, w = masks.shape

        x1, y1, x2, y2 = boxes[:, 0][:, None, None], boxes[:, 1][:, None, None], boxes[:, 2][:, None, None], boxes[:,
                                                                                                             3][:, None,
                                                                                                             None]
        r = np.arange(w)[None, None, :]
        c = np.arange(h)[None, :, None]

        in_box = (r >= x1) & (r < x2) & (c >= y1) & (c < y2)

        return masks * in_box

    @staticmethod
    def crop_maskV1(masks, boxes):
        """
        è£å‰ªæ©è†œï¼Œä½¿å…¶ä¸è¾¹ç•Œæ¡†å¯¹é½
        Args:
            masks (Numpy.ndarray): [n, h, w] æ©è†œæ•°ç»„
            boxes (Numpy.ndarray): [n, 4] è¾¹ç•Œæ¡†
        Returns:
            (Numpy.ndarray): è£å‰ªåçš„æ©è†œ
        """
        n, h, w = masks.shape
        x1, y1, x2, y2 = np.split(boxes[:, :, None], 4, 1)
        r = np.arange(w, dtype=x1.dtype)[None, None, :]
        c = np.arange(h, dtype=x1.dtype)[None, :, None]
        return masks * ((r >= x1) * (r < x2) * (c >= y1) * (c < y2))

    def process_mask(self, protos, masks_in, bboxes, im0_shape):
        """
        å¤„ç†æ¨¡å‹è¾“å‡ºçš„æ©è†œ
        Args:
            protos (numpy.ndarray): [mask_dim, mask_h, mask_w] æ©è†œåŸå‹
            masks_in (numpy.ndarray): [n, mask_dim] æ©è†œæ•°é‡
            bboxes (numpy.ndarray): ç¼©æ”¾åˆ°åŸå§‹å›¾åƒå°ºå¯¸çš„è¾¹ç•Œæ¡†
            im0_shape (tuple): åŸå§‹è¾“å…¥å›¾åƒçš„å°ºå¯¸ (h,w,c)
        Returns:
            (numpy.ndarray): å¤„ç†åçš„æ©è†œ
        """
        c, mh, mw = protos.shape
        masks = np.matmul(masks_in, protos.reshape((c, -1))).reshape((-1, mh, mw)).transpose(1, 2, 0)  # HWN
        masks = np.ascontiguousarray(masks)
        masks = self.scale_mask(masks, im0_shape)  # å°†æ©è†œä» P3 å°ºå¯¸ç¼©æ”¾åˆ°åŸå§‹è¾“å…¥å›¾åƒå¤§å°
        masks = np.einsum("HWN -> NHW", masks)  # HWN -> NHW

        masks = self.crop_mask(masks, bboxes)  # è£å‰ªæ©è†œ
        masks = np.greater(masks, 0.5)
        masks = masks[0:1]
        # print(masks.shape)
        # arr_tensor = torch.tensor(masks).cuda()
        # result_tensor = torch.any(arr_tensor, dim=0).to(dtype=torch.uint8)
        # masks = result_tensor.cpu().numpy()
        # masks = np.bitwise_or.reduce(masks, axis=0)
        # masks = np.max(masks, axis=0)
        # masks = np.array(masks*255,dtype=np.uint8)
        return masks  # è¿”å›äºŒå€¼åŒ–åçš„æ©è†œ

    @staticmethod
    def scale_mask(masks, im0_shape, ratio_pad=None):
        """
        å°†æ©è†œç¼©æ”¾è‡³åŸå§‹å›¾åƒå¤§å°
        Args:
            masks (np.ndarray): ç¼©æ”¾å’Œå¡«å……åçš„æ©è†œ
            im0_shape (tuple): åŸå§‹å›¾åƒå¤§å°
            ratio_pad (tuple): å¡«å……ä¸åŸå§‹å›¾åƒçš„æ¯”ä¾‹
        Returns:
            masks (np.ndarray): ç¼©æ”¾åçš„æ©è†œ
        """
        im1_shape = masks.shape[:2]
        if ratio_pad is None:  # è®¡ç®—æ¯”ä¾‹
            gain = min(im1_shape[0] / im0_shape[0], im1_shape[1] / im0_shape[1])  # æ¯”ä¾‹
            pad = (im1_shape[1] - im0_shape[1] * gain) / 2, (im1_shape[0] - im0_shape[0] * gain) / 2  # å¡«å……
        else:
            pad = ratio_pad[1]

        # è®¡ç®—æ©è†œçš„è¾¹ç•Œ
        top, left = int(round(pad[1] - 0.1)), int(round(pad[0] - 0.1))  # y, x
        bottom, right = int(round(im1_shape[0] - pad[1] + 0.1)), int(round(im1_shape[1] - pad[0] + 0.1))
        if len(masks.shape) < 2:
            raise ValueError(f'"len of masks shape" åº”è¯¥æ˜¯ 2 æˆ– 3ï¼Œä½†å¾—åˆ° {len(masks.shape)}')
        masks = masks[top:bottom, left:right]
        masks = cv2.resize(
            masks, (im0_shape[1], im0_shape[0]), interpolation=cv2.INTER_LINEAR
        )  # ä½¿ç”¨ INTER_LINEAR æ’å€¼è°ƒæ•´å¤§å°
        if len(masks.shape) == 2:
            masks = masks[:, :, None]
        return masks

    def draw_and_visualize(self, im, bboxes, segments, vis=False, save=True):
        """
        ç»˜åˆ¶å’Œå¯è§†åŒ–ç»“æœ
        Args:
            im (np.ndarray): åŸå§‹å›¾åƒï¼Œå½¢çŠ¶ä¸º [h, w, c]
            bboxes (numpy.ndarray): [n, 4]ï¼Œn æ˜¯è¾¹ç•Œæ¡†æ•°é‡
            segments (List): åˆ†å‰²åŒºåŸŸçš„åˆ—è¡¨
            vis (bool): æ˜¯å¦ä½¿ç”¨ OpenCV æ˜¾ç¤ºå›¾åƒ
            save (bool): æ˜¯å¦ä¿å­˜å¸¦æ³¨é‡Šçš„å›¾åƒ
        Returns:
            None
        """
        # åˆ›å»ºå›¾åƒå‰¯æœ¬
        im_canvas = im.copy()

        for (*box, conf, cls_), segment in zip(bboxes, segments):
            # è·å–ç±»åˆ«å¯¹åº”çš„é¢œè‰²
            color = self.get_color_for_class(int(cls_))

            # ç»˜åˆ¶è½®å»“å’Œå¡«å……æ©è†œ
            # cv2.polylines(im, np.int32([segment]), True, (255, 255, 255), 2)  # ç»˜åˆ¶ç™½è‰²è¾¹æ¡†
            cv2.fillPoly(im_canvas, np.int32([segment]), color)  # ä½¿ç”¨ç±»åˆ«å¯¹åº”çš„é¢œè‰²å¡«å……å¤šè¾¹å½¢

            # ç»˜åˆ¶è¾¹ç•Œæ¡†
            cv2.rectangle(im, (int(box[0]), int(box[1])), (int(box[2]), int(box[3])), color, 1, cv2.LINE_AA)
            # åœ¨å›¾åƒä¸Šç»˜åˆ¶ç±»åˆ«åç§°å’Œç½®ä¿¡åº¦
            cv2.putText(im, f"{self.classes[cls_]}: {conf:.3f}", (int(box[0]), int(box[1] - 9)),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1, cv2.LINE_AA)

        # å°†å›¾åƒå’Œç»˜åˆ¶çš„å¤šè¾¹å½¢æ··åˆ
        im = cv2.addWeighted(im_canvas, 0.3, im, 0.7, 0)

        # æ˜¾ç¤ºå›¾åƒ
        if vis:
            ima = cv2.resize(im, (1280, 720))
            cv2.imshow("seg_result_picture", ima)
            cv2.waitKey(0)
            cv2.destroyAllWindows()

        # ä¿å­˜å›¾åƒ
        if save:
            cv2.imwrite("seg_result_picture.jpg", im)


if __name__ == "__main__":
    # åˆ›å»ºå‘½ä»¤è¡Œå‚æ•°è§£æå™¨
    parser = argparse.ArgumentParser()
    parser.add_argument("--model", type=str, default=r"yolo11n-seg.onnx", help="ONNX æ¨¡å‹è·¯å¾„")
    parser.add_argument("--source", type=str,
                        default=r"C:\Users\84728\Desktop\land\land_in2.jpg",
                        help="è¾“å…¥å›¾åƒè·¯å¾„")
    parser.add_argument("--conf", type=float, default=0.6, help="ç½®ä¿¡åº¦é˜ˆå€¼")
    parser.add_argument("--iou", type=float, default=0.45, help="NMS çš„ IoU é˜ˆå€¼")
    args = parser.parse_args()

    # åŠ è½½æ¨¡å‹
    model = YOLO11Seg(args.model)

    # ä½¿ç”¨ OpenCV è¯»å–å›¾åƒ
    img = cv2.imread(args.source)

    # æ¨¡å‹æ¨ç†
    print("å¼€å§‹æ¨ç†...")
    t1 = time.time()
    boxes, segments, _ = model(img, conf_threshold=args.conf, iou_threshold=args.iou)
    print(f"æ¨ç†å®Œæˆï¼Œè€—æ—¶ {time.time() - t1:.3f} ç§’")
    t1 = time.time()
    _, _, _ = model(img, conf_threshold=args.conf, iou_threshold=args.iou)
    print(f"æ¨ç†å®Œæˆï¼Œè€—æ—¶ {time.time() - t1:.3f} ç§’")
    t1 = time.time()
    boxes, segments, _ = model(img, conf_threshold=args.conf, iou_threshold=args.iou)
    print(f"æ¨ç†å®Œæˆï¼Œè€—æ—¶ {time.time() - t1:.3f} ç§’")
    t1 = time.time()
    _, _, _ = model(img, conf_threshold=args.conf, iou_threshold=args.iou)
    print(f"æ¨ç†å®Œæˆï¼Œè€—æ—¶ {time.time() - t1:.3f} ç§’")
    t1 = time.time()
    boxes, segments, _ = model(img, conf_threshold=args.conf, iou_threshold=args.iou)
    print(f"æ¨ç†å®Œæˆï¼Œè€—æ—¶ {time.time() - t1:.3f} ç§’")
    t1 = time.time()
    _, _, _ = model(img, conf_threshold=args.conf, iou_threshold=args.iou)
    print(f"æ¨ç†å®Œæˆï¼Œè€—æ—¶ {time.time() - t1:.3f} ç§’")
    t1 = time.time()
    boxes, segments, _ = model(img, conf_threshold=args.conf, iou_threshold=args.iou)
    print(f"æ¨ç†å®Œæˆï¼Œè€—æ—¶ {time.time() - t1:.3f} ç§’")
    t1 = time.time()
    _, _, _ = model(img, conf_threshold=args.conf, iou_threshold=args.iou)
    print(f"æ¨ç†å®Œæˆï¼Œè€—æ—¶ {time.time() - t1:.3f} ç§’")
    t1 = time.time()
    boxes, segments, _ = model(img, conf_threshold=args.conf, iou_threshold=args.iou)
    print(f"æ¨ç†å®Œæˆï¼Œè€—æ—¶ {time.time() - t1:.3f} ç§’")
    t1 = time.time()
    _, _, _ = model(img, conf_threshold=args.conf, iou_threshold=args.iou)
    print(f"æ¨ç†å®Œæˆï¼Œè€—æ—¶ {time.time() - t1:.3f} ç§’")
    t1 = time.time()
    boxes, segments, _ = model(img, conf_threshold=args.conf, iou_threshold=args.iou)
    print(f"æ¨ç†å®Œæˆï¼Œè€—æ—¶ {time.time() - t1:.3f} ç§’")
    t1 = time.time()
    _, _, _ = model(img, conf_threshold=args.conf, iou_threshold=args.iou)
    print(f"æ¨ç†å®Œæˆï¼Œè€—æ—¶ {time.time() - t1:.3f} ç§’")
    t1 = time.time()
    boxes, segments, _ = model(img, conf_threshold=args.conf, iou_threshold=args.iou)
    print(f"æ¨ç†å®Œæˆï¼Œè€—æ—¶ {time.time() - t1:.3f} ç§’")
    t1 = time.time()
    _, _, _ = model(img, conf_threshold=args.conf, iou_threshold=args.iou)
    print(f"æ¨ç†å®Œæˆï¼Œè€—æ—¶ {time.time() - t1:.3f} ç§’")
    # # å¦‚æœæ£€æµ‹åˆ°ç›®æ ‡ï¼Œç»˜åˆ¶è¾¹ç•Œæ¡†å’Œåˆ†å‰²åŒºåŸŸ
    # if len(boxes) > 0:
    #     model.draw_and_visualize(img, boxes, segments, vis=True, save=False)

